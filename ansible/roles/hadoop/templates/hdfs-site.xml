<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
    <property>
        <name>dfs.nameservices</name>
        <value>{{ hadoop['nameservice_id'] }}</value>
    </property>

    <property>
        <name>dfs.ha.namenodes.{{ hadoop['nameservice_id'] }}</name>
        <value>{{ groups.masters | join(',') }}</value>
    </property>

    <property>
        <name>dfs.blocksize</name>
        <value>{{ hadoop['dfs_blocksize'] }}</value>
    </property>

    <property>
        <name>dfs.permissions.superusergroup</name>
        <value>{{ hadoop['dfs_permissions_superusergroup'] }}</value>
    </property>

    <property>
        <name>dfs.ha.automatic-failover.enabled</name>
        <value>true</value>
    </property>

    <property>
        <name>ha.zookeeper.quorum</name>
        <value>{{ groups.zookeepers | join(':' ~ hadoop['zookeeper_clientport'] + ',') }}:{{hadoop['zookeeper_clientport'] }}
        </value>
    </property>

    {% for host in groups['masters'] %}
    <property>
        <name>dfs.namenode.rpc-address.{{ hadoop['nameservice_id'] }}.{{ host }}</name>
        <value>{{ host }}:{{ hadoop['fs_default_FS_port'] }}</value>
    </property>
    {% endfor %}

    {% for host in groups['masters'] %}
    <property>
        <name>dfs.namenode.http-address.{{ hadoop['nameservice_id'] }}.{{ host }}</name>
        <value>{{ host }}:{{ hadoop['dfs_namenode_http_address_port'] }}</value>
    </property>
    {% endfor %}

    <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://{{ groups.qjournals | join(':' ~ hadoop['qjournal_port'] + ';') }}:{{ hadoop['qjournal_port'] }}/{{ hadoop['nameservice_id'] }}
        </value>
    </property>

    <property>
        <name>dfs.journalnode.edits.dir</name>
        <value>{{ hadoop['dfs_journalnode_edits_dir'] }}</value>
    </property>

    <property>
        <name>dfs.client.failover.proxy.provider.{{ hadoop['nameservice_id'] }}</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    <property>
        <name>dfs.ha.fencing.methods</name>
        <value>shell(/bin/true)</value>
    </property>

    <property>
        <name>dfs.ha.zkfc.port</name>
        <value>{{ hadoop['dfs_ha_zkfc_port'] }}</value>
    </property>

    <property>
        <name>dfs.datanode.address</name>
        <value>0.0.0.0:{{ hadoop['dfs_datanode_address_port'] }}</value>
    </property>
    <property>
        <name>dfs.datanode.http.address</name>
        <value>0.0.0.0:{{ hadoop['dfs_datanode_http_address_port'] }}</value>
    </property>
    <property>
        <name>dfs.datanode.ipc.address</name>
        <value>0.0.0.0:{{ hadoop['dfs_datanode_ipc_address_port'] }}</value>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>{{ hadoop['dfs_replication'] }}</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>{{ hadoop['dfs_namenode_name_dir'] | join(',') }}</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>{{ hadoop['dfs_datanode_data_dir'] | join(',') }}</value>
    </property>
</configuration>
